<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
<title>Archive System</title>

<para>One part of CSS is the Archive System, specifically the
<quote>Best Ever Archive Toolset, yet (BEAUTY)</quote><indexterm><primary>BEAUTY</primary></indexterm>
that was developed as a replacement for the Channel Archiver.
An Archive Engine takes PV data samples from a front-end computer, for example from EPICS IOCs via Channel Access,
and places them in some data storage, see <xref linkend="fig_archive"/>.
Archive client programs then access historic data samples in that storage.
In this system, the storage is a Relational Database (RDB)<indexterm><primary>Relational Database (RDB)</primary></indexterm>
like MySQL or Oracle.
Both the historic data of PVs and the Archive Engine configuration are stored in the relational database.
The engine configuration can be imported from an XML file format into the database, or it can be exported
from the database back into an XML file format for editing.
</para>

<para>Typical setups will include more than one Archive Engine, for example one sample engine per subsystem.
In principle, data providers other than archive engines can also write samples to the storage.
The CSS Data Browser is a generic client program for looking at archived data,
but fundamentally any program that has access to a relational database can be used
to create reports. A typical application might be JSP-based web reports of data.
</para>

<figure xml:id="fig_archive">  <title>Archive System Overview</title>
  <mediaobject>
    <imageobject><imagedata fileref="archive.png" width="100%" format="PNG"/></imageobject>
  </mediaobject>
</figure>

<para>There are two integration points with the legacy Channel Archiver<indexterm><primary>Channel Archiver</primary></indexterm>:
The EngineConfigImport tool can import existing archive engine configuration files into the RDB because the
XML file format is compatible with the Channel Archiver.
The Data Browser is capable of reading data from the relational database as well as from the Channel Archiver's
XML-RPC-based data server, thereby allowing nearly transparent access to both <quote>old</quote> and <quote>new</quote>
data.
</para>


<sect1>  <title>Building the Tools</title>

<para>The Archive Engine is the central sampling tool that reads values from PVs and writes them to the archive data storage.
It is implemented as an Eclipse product.
You will probably also want to build EngineConfigImport, 
the tool used to import engine configuration files into the relational database.
They are defined in these product files:

<programlisting>org.csstudio.archive.engine/ArchiveEngine.product
org.csstudio.archive.rdb/EngineConfigImport.product
</programlisting>

For first tests, you can run both tools from within the Eclipse IDE as described in
<xref linkend="chap_compiling"/>, <xref linkend="sec_runnning_in_ide"/>,
but note that you will have to provide command-line arguments to them.
After first tests are successful, you can export from from the IDE as described in the same section.
Finally, you will need one of the CSS end-user products that includes the Data Browser to
look at the archived data, but for now we concentrate on the tools
needed to collect data.
</para>
</sect1>


<sect1>  <title>Relational Database Setup</title>

<para>Before using the archive tools, you need to create the required table structure in your RDB.
Currently MySQL, Oracle and PostgreSQL are supported.
</para>

<para>The commands for creating the RDB table structures are in files in the <code>dbd</code> sub-directory
of the plugin <code>org.csstudio.archive.rdb</code>.
Basic RDB administration skills will be required because you need to create the table structure by using one of these files,
and will probably also need to create two accounts: One account for the archive engines that has write access to the tables,
and another read-only account for archive clients like the CSS Data Browser to read archived data.
</para>

<para>The RDB tables for the different database dialects are very similar with the exception of the 
<code>TIMESTAMP</code> used to store the time stamps of samples. While the Oracle time stamp data type already offers nanosecond detail,
the MySQL data type of the same name only covers seconds.
The MySQL tables therefore have an added <code>nanosecs</code> column for this purpose.
There are a few more differences in the SQL dialects, but the Archive Engine, CSS Data Browser etc. auto-configure based on the database URL.
</para>

<para>The setup for MySQL might be the easiest at least for development and testing, but it has limitations.
All samples for all channels are written to one <code>sample</code> table. By default, MySQL table sizes are limited to 4GB
(See MySQL <code>show table status</code> command, column <quote>Max_data_length</quote>).
While this can be adjusted, I believe there is still a limit of 4G rows (=samples).
Furthermore, while it will be almost trivial to enter something like
<programlisting><![CDATA[DELETE FROM sample WHERE smpl_time < ...
]]></programlisting>
to delete older samples, this will either not free up any space or require an added <code>OPTIMIZE</code> rebuild, which takes a very long time.
</para>

<para>One reason for using Oracle lies in its support for partitioning: While the sample <code>sample</code> appears as one table,
it can be spread over several table partitions based on the sample time and channel name.
Spreading by channel name might improve performance because several channels can be written
in parallel to different disk locations. Partitioning by time allows quick removal of older samples.
In addition, for Oracle the archive data readout implementation used by the Data Browser
(plugin <code>org.csstudio.archivereader.rdb</code>)
supports a stored procedure for server-side data reduction which is not available for MySQL.
</para>

<para>Whatever database you use, in the end you need to provide all CSS archive tools with the following configuration information:</para>
<itemizedlist>
<listitem>URL:
Depending on the RDB system this will be a URL of the format
<programlisting><![CDATA[jdbc:mysql://[host]:[port]/[database]?user=[user]&password=[pw]
]]></programlisting>
for MySQL or
<programlisting>jdbc:oracle:thin:@//[host]:[port]/[database]
</programlisting>
for Oracle. The archive tools will use the start of that URL to detect the RDB dialect: MySQL, Oracle, PostgreSQL.
</listitem>
<listitem>User name: A user name known to the RDB. Typically you configure at least one user with write access for archive engines, and one
with read-only access for client programs.</listitem>
<listitem>Password: Associated password</listitem>
<listitem>Schema: A prefix for RDB table names that is for example often needed by Oracle to access the tables.</listitem>
</itemizedlist>

<para>The command-line tools will accept these parameters on the command-line.
For other tools, refer to <xref linkend="ch_preferences"/>
</para>
</sect1>


<sect1>  <title>Archive Engine Configuration</title>

<para>Each sample engine configuration identified by a name, for example
<quote>WaterSystem</quote>. Inside the RDB the configuration is actually
identified by a unique numeric ID, but most end user tools only see the
name of the configuration.
</para>

<sect2>  <title>Channel Groups</title>
<para>Each archive engine configuration is comprised of groups.
An engine configuration has at least one group, maybe more, and channels are
then added to these groups. Groups are not hierarchical: There are no sub-groups
within groups, only one list of groups.</para>

<para>Groups are primarily used to organize the configuration.
For example, a <quote>WaterSystem</quote> sample engine configuration might
have groups <quote>WestSector</quote>, <quote>MainBuilding</quote> etc. to hold
the channels for the respective section of the water system.
Note that this arrangement of channels into groups is <emphasis>not visible to end users of the data</emphasis>!
The separation of channels into groups inside the sample engine configuration is
mostly meant for the engineers who maintain the sample engine configuration,
grouping the channels by location along the machine, but associated front-end computer,
or by functionality.
</para>

<para>There is one functional aspects of groups: Archiving of all channels in a group
can be enabled or disabled based on one channel in the group.
When placing all channels of a power supply in a group, this feature can be used to
suppress archiving of noise while the power supply is off by using a channel
that indicates whether the power supply is on or off to enable the archive channel group.
</para>
</sect2>

<sect2 xml:id="sec_arch_channel">  <title>Channels</title>
<para>A channel in the archive system is basically the data provided by one Process Variable.
A channel is identified by its name, which has to be a valid PV name for the control system,
a PV that you can also read with other control system tools.
The samples stored for the channel include not only the value, for example a number,
but also the time stamp, status/severity and meta data like engineering units and display ranges.
The time stamp, status/severity and value are stored with each sample.
The meta data is only stored once at startup of the archive engine because the original
implementation for EPICS did not offer an efficient way to monitor for changes in the
meta data.
</para>

<para>When a channel sends a new value to the archive engine is somewhat outside of the
control of the archive engine. The control system software on the front end controls this.
For EPICS record, the <code>SCAN</code> field in combination with the <code>ADEL</code> field
of analog records determines when a new value is sent to the archive engine.</para>

<para>The meta data for a channel is similarly controlled by the front end device that
provides the data. For EPICS records, the <code>EGU</code>, <code>HOPR</code> and other fields
have to be used to configure these.</para>
</sect2>


<sect2>  <title>Duplicate Channels</title>
<para>The RDB configuration allows for multiple sample engines.
Each sample engine has one or more groups of channels, and each group has one or more channels.
A channel, however, <emphasis>can only be archived once</emphasis>. It is illegal to list a channel
in more than one group or under more than one sample engine.
</para>
</sect2>
</sect1>


<sect1>  <title>Sample Modes</title>
<para>The archive engine supports several sample modes, i.e. ways in which it decides what
samples should be written to the archive data store.
As just mentioned in <xref linkend="sec_arch_channel"/>, the front-end computer decides which
updates to send to the archive engine. In an ideal world, every such change would be meaningful
and there were infinite resources (CPU power, disk space, network bandwidth) to store every
change until eternity.
In reality, it is often better to store fewer samples.
</para>

<sect2>  <title>Monitored</title>
<para>In monitored mode, each received sample is written to the store. With a perfectly
configured data source, for example an EPICS <code>ADEL</code> that only passes
significant changes to the archive engine, this mode is ideal:
Significant changes in value are written to the archive, while noise in the signal
is suppressed to minimize wasted resources.
</para>
</sect2>

<sect2>  <title>Monitored With Threshold</title>
<para>This mode is also monitored, but adding another value change threshold filter.
Ideally, the front-end computer already performs the thresholding, so only significant
changes are sent over the network to the archive engine.
In some cases, however, this is not possible, and for those cases the archive engine
itself can check for changes in the value, writing only samples that differ from the
last written sample by at least some configurable margin.
</para>
</sect2>

<sect2>  <title>Scanned/Sampled</title>
<para>In scanned mode, the archive engine still receives each update from the data source,
but it only writes the most recent sample at periodic times, for example once every 5 minutes.
</para>
<para>This mode is a compromise. If a channel has no significant change for hours, why
should the uninteresting changes fill disk space every 5 minutes?
On the other hand, if an important even happens that produces a brief <quote>blip</quote>
in the data, the archived data is likely to miss it when only storing a value every 5 minutes.
</para>
<para>This mode was created for channels which do not have a good dead-band configuration,
where using the monitored mode would add too many samples to the archive.
Periodic sampling is clearly imperfect, but sometimes a workable compromise.</para>
</sect2>
</sect1>




<sect1>  <title>Editing the Configuration</title>
</sect1>



<sect1>  <title>Running Archive Engines</title>

Settings
Database connection
logging
EPICS

<sect2>  <title>Engine Web Server</title>
<para>Each sample engine has a built-in web server for status information
and basic remote control of the engine. When starting the engine on a host,
the port number for this HTTPD must be provided.
The sample engine URL configured in the RDB should match the format
<programlisting><![CDATA[http://<host>:<port>/main]]></programlisting>
Ideally, a future tool will automatically start engines on the configured host and port.
</para>
</sect2>

</sect1>




</chapter>
